![Python](https://img.shields.io/badge/Python-3.9-blue?logo=python) ![PySpark](https://img.shields.io/badge/PySpark-3.3-orange?logo=apache-spark) ![AWS](https://img.shields.io/badge/AWS-Cloud-yellow?logo=amazon-aws) ![Status](https://img.shields.io/badge/Status-Projeto_Conclu√≠do-green)

# An√°lise Estrat√©gica de Filmes: Decifrando o ROI e as Tend√™ncias de Mercado na AWS

Este projeto apresenta uma **an√°lise de ponta a ponta sobre o desempenho financeiro e de mercado de filmes dos g√™neros Crime e Guerra** (e seus sub-g√™neros associados), transformando um desafio de neg√≥cio complexo em **recomenda√ß√µes estrat√©gicas e acion√°veis**. A an√°lise foi sustentada pela constru√ß√£o de um **Data Lake serverless na AWS**, demonstrando um fluxo de trabalho completo que vai da engenharia robusta √† gera√ß√£o de insights de alto valor para a tomada de decis√£o. A investiga√ß√£o culmina em um relat√≥rio executivo que responde a quest√µes cr√≠ticas sobre otimiza√ß√£o de or√ßamento, potencial de franquias e oportunidades de mercado.

<br>

## üí• O Problema de Neg√≥cio

Um est√∫dio de cinema fict√≠cio precisa de direcionamento estrat√©gico para futuros investimentos. Para isso, era necess√°rio responder a perguntas cr√≠ticas sobre o desempenho hist√≥rico de filmes de Crime e Guerra, envolvendo performance financeira (ROI, Receita), popularidade, impacto de franquias e tend√™ncias de mercado.

---

## üìà Principais Resultados e An√°lises

A an√°lise dos dados, consolidada em um relat√≥rio executivo, revelou padr√µes claros e permitiu a formula√ß√£o de diretrizes estrat√©gicas para o est√∫dio. O projeto completo pode ser acessado abaixo, seguido dos destaques visuais.

**[Acesse o Relat√≥rio Executivo completo em PDF aqui](./Sprint10/desafio/relatorio/Felipe.Reis-Relat√≥rio-Dashboard-Sprint10.pdf)**

---

### Destaques da An√°lise

#### 1. Dispers√£o entre Or√ßamento e Resultado Financeiro: padr√µes e desvios de ROI
*A an√°lise mostra que a hip√≥tese de que or√ßamentos maiores garantem lucros maiores nem sempre √© verdadeira. G√™neros como `History` e `Sci-Fi` demonstram um equil√≠brio interessante, com `History` apresentando alto ROI com or√ßamentos moderados. Em contraste, `Adventure` e `Sport` mostram alto investimento com ROI negativo, indicando maior risco.*

![Gr√°fico de ROI vs Or√ßamento](./Sprint10/desafio/1ROI.png)

#### 2. Receitas medianas: g√™neros associados a Crime e Guerra
*Ao analisar as receitas medianas, a combina√ß√£o de `Crime` com `Sci-Fi` se destaca como a mais lucrativa. `War` combinado com `Thriller` tamb√©m mostra relev√¢ncia. Este gr√°fico √© fundamental para identificar nichos de mercado e combina√ß√µes de g√™nero com maior potencial de arrecada√ß√£o.*

![Gr√°fico de Receitas por G√™nero Associado](./Sprint10/desafio/2genero_associado.png)

#### 3. An√°lise Geogr√°fica: Mediana de ROI, por g√™nero de filme
*Embora a maior parte da produ√ß√£o se concentre no eixo EUA-Europa, a an√°lise de ROI por localiza√ß√£o geogr√°fica destaca oportunidades promissoras fora do eixo principal. Produ√ß√µes de `War` no Leste Europeu e de `Crime` na Oceania, por exemplo, apresentam um ROI mediano interessante, sugerindo mercados com potencial a ser explorado.*

![Mapa de ROI por G√™nero](./Sprint10/desafio/4mapa.png)

---

### Recomenda√ß√µes Estrat√©gicas Acion√°veis:
* **Otimiza√ß√£o de Or√ßamento:** Filmes com or√ßamentos moderados (entre $20M e $60M) apresentaram o maior Retorno Sobre o Investimento (ROI), sugerindo um "ponto √≥timo" para investimentos futuros, especialmente em g√™neros como `History`.
* **Potencial de Franquias:** Franquias demonstraram ser significativamente mais lucrativas que filmes √∫nicos. A an√°lise temporal sugere que o sucesso √© maior quando o intervalo entre lan√ßamentos √© inferior a 4 anos, indicando a import√¢ncia de um planejamento de ciclo de vida.
* **Explora√ß√£o de Nichos e Mercados:** A combina√ß√£o de g√™neros como `Crime` com `Sci-Fi` ou `History` apresenta alto potencial financeiro. Adicionalmente, mercados fora do eixo tradicional (EUA, Europa Ocidental) como o Leste Europeu e a Oceania mostram oportunidades de ROI promissoras que merecem uma an√°lise de investimento.

---

## üéØ A Solu√ß√£o: An√°lise de Ponta a Ponta

Para entregar esses insights, foi constru√≠do um **Data Lake serverless de ponta a ponta na AWS**. A solu√ß√£o completa envolve um pipeline automatizado que ingere dados de fontes diversas, os processa e modela em um esquema dimensional robusto, e os disponibiliza para an√°lise em um relat√≥rio no Amazon QuickSight.

---

## üèóÔ∏è A Engenharia por Tr√°s da An√°lise: Arquitetura do Pipeline

A an√°lise foi sustentada por uma arquitetura de dados serverless, garantindo escalabilidade, automa√ß√£o e baixo custo operacional.

**Fluxo de Dados:**
`Fontes (CSV/API) -> S3 (Raw) -> AWS Glue (PySpark) -> S3 (Trusted) -> AWS Glue (PySpark) -> S3 (Refined) -> Athena -> QuickSight`

*Insira aqui o diagrama da arquitetura. Ferramentas como draw.io ou Miro s√£o √≥timas para isso.*
`![Arquitetura do Data Lake](./caminho/para/sua/imagem_arquitetura.png)`

---

## üõ†Ô∏è Tecnologias Utilizadas

* **Cloud & ETL:** AWS S3, AWS Glue, AWS Lambda, AWS EventBridge, AWS Athena
* **Processamento de Dados:** Apache Spark (PySpark)
* **Visualiza√ß√£o (BI):** Amazon QuickSight
* **Linguagem & Bibliotecas:** Python (Pandas, Boto3, Requests)
* **Containeriza√ß√£o:** Docker
* **Automa√ß√£o e Ambiente:** Shell Script, Linux

---

## üõ£Ô∏è Etapas do Pipeline de Dados

O desenvolvimento do Data Lake seguiu um processo estruturado, desde a ingest√£o dos dados brutos at√© a camada de apresenta√ß√£o.

* **1. Ingest√£o Automatizada na Camada Raw:** O pipeline inicia com a ingest√£o dos dados brutos (CSV do IMDB e JSON da API do TMDB) na camada `Raw` do S3. Scripts em Python com Boto3 foram usados para automatizar o provisionamento de buckets e o upload dos dados em uma estrutura particionada por data. Todo o processo foi containerizado com **Docker** para assegurar a reprodutibilidade.

* **2. Enriquecimento de Dados via API com Pipeline Serverless:** Para enriquecer os dados, foi constru√≠do um pipeline de ingest√£o serverless com **AWS Lambda** para extrair informa√ß√µes da API do TMDB. A orquestra√ß√£o foi feita com **AWS EventBridge**, que agendou execu√ß√µes parametrizadas para lidar com os limites da API e o timeout da Lambda de forma resiliente.

* **3. Constru√ß√£o da Camada Trusted com AWS Glue:** Os dados da camada `Raw` foram processados por Jobs no **AWS Glue** utilizando **PySpark**. Foram aplicadas regras de neg√≥cio como limpeza de nulos, padroniza√ß√£o de campos e defini√ß√£o de schemas para garantir a consist√™ncia. Os dados tratados foram salvos em formato **Parquet** na camada `Trusted`.

* **4. Constru√ß√£o da Camada Refined e Modelagem Dimensional:** Na etapa final de engenharia, os dados da camada `Trusted` foram unidos, enriquecidos com campos calculados de neg√≥cio (como ROI) e modelados em um **esquema Galaxy com tabelas ponte**. Esta modelagem avan√ßada foi necess√°ria para garantir a precis√£o das an√°lises com relacionamentos complexos, com a integridade validada via **AWS Athena**.

* **5. Visualiza√ß√£o e Storytelling com Amazon QuickSight:** Os dados da camada `Refined` foram consumidos pelo **Amazon QuickSight** para a constru√ß√£o de um relat√≥rio executivo. O design foi focado em **storytelling com dados**, apresentando as an√°lises de forma contextualizada para culminar nas conclus√µes e recomenda√ß√µes acion√°veis.

---

## üöÄ Como Executar o Projeto

Para replicar o ambiente de desenvolvimento e execu√ß√£o dos scripts locais:

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/felipecsr/analise-desempenho-filmes-aws.git](https://github.com/felipecsr/analise-desempenho-filmes-aws.git)
    cd analise-desempenho-filmes-aws
    ```
    *(Lembre-se de ajustar a URL acima ap√≥s renomear seu reposit√≥rio)*

2.  **Configure suas credenciais AWS:**
    Certifique-se de que suas credenciais da AWS estejam configuradas no ambiente (via `aws configure` ou vari√°veis de ambiente).

3.  **Instale as depend√™ncias:**
    ```bash
    pip install -r requirements.txt
    ```
    *Nota: Um arquivo `requirements.txt` √© fornecido para documentar as bibliotecas Python utilizadas nos scripts locais, garantindo a reprodutibilidade do ambiente.*

4.  **Execute os scripts e Jobs:**
    Siga as instru√ß√µes detalhadas nos READMEs de cada sprint para executar os scripts locais e configurar os Jobs no AWS Glue.

---

## üìÇ Detalhes do Desenvolvimento (Sprints)

Este projeto foi o desafio final de um programa de bolsas de 20 semanas em Data & Analytics na AWS. As 5 etapas finais focaram na constru√ß√£o deste pipeline, enquanto as 5 etapas iniciais consolidaram os fundamentos t√©cnicos necess√°rios para sua execu√ß√£o.

#### Fundamentos T√©cnicos (Sprints 1-5)
As sprints iniciais focaram no desenvolvimento de compet√™ncias fundamentais em engenharia e an√°lise de dados, incluindo **Linux & Shell Script, modelagem de dados com SQL, ETL e an√°lise com Python & Pandas, e containeriza√ß√£o com Docker**, que formaram a base para a execu√ß√£o deste projeto.

#### Etapas de Constru√ß√£o do Projeto (Sprints 6-10)
O "di√°rio de bordo" detalhado, com c√≥digos, desafios e aprendizados de cada fase da constru√ß√£o do Data Lake, pode ser encontrado nos links abaixo:

* [**Sprint 06:** Defini√ß√£o do Escopo e Ingest√£o Inicial no S3](./Sprint06/Desafio/README.md)
* [**Sprint 07:** Extra√ß√£o de Dados via API com Lambda e EventBridge](./Sprint07/Desafio/README.md)
* [**Sprint 08:** Constru√ß√£o da Camada Trusted com AWS Glue e PySpark](./Sprint08/desafio/README.md)
* [**Sprint 09:** Modelagem Dimensional e Constru√ß√£o da Camada Refined](./Sprint09/desafio/README.md)
* [**Sprint 10:** Visualiza√ß√£o de Dados com QuickSight e Finaliza√ß√£o](./Sprint10/desafio/README.md)

