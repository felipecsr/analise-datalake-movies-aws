
# ğŸ¯ Objetivo

Este README documenta a resuloÃ§Ã£o do desafio da Sprint 03.  
Trata-se de um `ETL` **(ExtraÃ§Ã£o, tratamento e carregamento)**, ou seja: acesso de leitura via Python, extraÃ§Ã£o de dados de um CSV (dataset), tratamentos de duplicidades e tipos de dados, e disponibilizaÃ§Ã£o para anÃ¡lise.  
Na etapa de `anÃ¡lise dos dados`, atravÃ©s de bibliotecas tÃ­picas de anÃ¡lise de dados, chegamos em listas, valores, grÃ¡ficos, para responder 7 questÃµes (etapa 2 a 8 do desafio). 

<br/>

# ğŸ²ğŸ“ğŸ“š ETL

### VeriricaÃ§Ã£o e tratamento de inconsistÃªncias

Foi necessÃ¡rio percorrer o *dataset* verificando se para todas as colunas existiam dados, e verificar, assim, a consistÃªncia do conjunto de dados. Neste tÃ³pico, trÃªs linhas foram capturadas pelo teste, onde atravÃ©s de anÃ¡lise visual da tabela, constatei que apenas uma delas necessitava de tratamento, a linha 10472.

Esse tratamento foi atravÃ©s da funÃ§Ã£o `shift` (que alinha os dados para a coluna seguinte, Ã  direita) e inserÃ§Ã£o de um 'NaN' na segunda coluna que nÃ£o possuia a informaÃ§Ã£o adequada.

```python
# Tratamento da linha 10472 para corrigir a inconsistÃªncia
import pandas as pd

# Ler o arquivo CSV
data = pd.read_csv('googleplaystore.csv')

# FunÃ§Ã£o para corrigir a linha 10472
def corrigir_linha_10472(df):
    idx = 10472  # Ãndice da linha a ser corrigida
    if idx in df.index:
        print(f"Linha antes da correÃ§Ã£o:\n{df.loc[idx]}\n")
        
        # Manter o conteÃºdo da primeira coluna e preencher a segunda com 'NaN'
        df.loc[idx, df.columns[1:]] = df.loc[idx, df.columns[:-1]].astype(str).shift(1)
        df.loc[idx, 'Category'] = 'NaN'
        
        print(f"Linha apÃ³s a correÃ§Ã£o:\n{df.loc[idx]}\n")
    else:
        print("Linha 10472 nÃ£o encontrada no DataFrame.")
    
    return df

# Aplicar a correÃ§Ã£o na linha 10472
data = corrigir_linha_10472(data)

# Bloco de cÃ³digo para testar o DataFrame e confirmar que a linha 10472 foi tratada
def testar_dataframe_corrigido(df):
    # Verifica se a linha 10472 tem 13 elementos, incluindo NaNs, e imprime um resumo
    linha_10472 = df.loc[10472]
    num_elementos = len(linha_10472)  # Conta todos os elementos, incluindo NaNs
    print(f"Contagem de elementos na linha 10472 apÃ³s correÃ§Ã£o: {num_elementos}")
    if num_elementos == df.shape[1]:
        print("Linha 10472 foi tratada corretamente e nÃ£o Ã© mais inconsistente.")
    else:
        print("Linha 10472 ainda apresenta inconsistÃªncias.")

# Testar o DataFrame
testar_dataframe_corrigido(data)
```
<br/>


### Tratamento de duplicidades e formatos dos dados

Neste bloco de cÃ³digo, buscamos atravÃ©s da funÃ§Ã£o `drop_duplicates`a remoÃ§Ã£o de linhas idÃªnticas, e na sequÃªncia atravÃ©s das funÃ§Ãµes `astype` e `replace` a conversÃ£o dos formatos desejados, separando strings e valores inteiros e float.

``` python
# Bloco de cÃ³digo para tratamentos adicionais no DataFrame

# Remover duplicidades
data = data.drop_duplicates()

# Tratar a coluna 'Price': converter para string, remover o sÃ­mbolo '$' e converter para float
data['Price'] = data['Price'].astype(str).str.replace('$', '', regex=False).astype(float)

# Converter a coluna 'Reviews' para float e depois para int, tratando erros
data['Reviews'] = pd.to_numeric(data['Reviews'], errors='coerce').fillna(0).astype(int)

# Exibir mensagem de sucesso
def verificar_tratamentos(df):
    print("Tratamentos realizados com sucesso:")
    print(f"Total de linhas apÃ³s remoÃ§Ã£o de duplicidades: {df.shape[0]}")
    print(f"Tipo de dados da coluna 'Price': {df['Price'].dtype}")
    print(f"Tipo de dados da coluna 'Reviews': {df['Reviews'].dtype}")

# Verificar o DataFrame apÃ³s os tratamentos
verificar_tratamentos(data)
```
<br/>
<br/>


# ğŸ”ğŸ“Š AnÃ¡lise dos Dados (item 2 ao 8)

Nesta etapa, itens 2 ao 8, resolvemos 'exercÃ­cios' onde o objetivo era a obtenÃ§ao de respostas atravÃ©s das anÃ¡lises dos dados, gerando listas de nomes/ valores, e grÃ¡ficos.

### Aqui um exemplo, como o item 2 desta etapa do desafio:
Com o *dataframe* prÃ©-tratado e pronto para as anÃ¡lises, geramos um grÃ¡fico para obtenÃ§Ã£o da resposta desejada.

```python
import matplotlib.pyplot as plt

# Converter a coluna 'Installs' para string e remover caracteres indesejados apenas se necessÃ¡rio
data['Installs'] = data['Installs'].astype(str).str.replace(',', '').str.replace('+', '').astype(int)

# Selecionar os top 5 apps por nÃºmero de instalaÃ§Ãµes
top_5_apps = data.sort_values(by='Installs', ascending=False).head(5)

# Criar o grÃ¡fico de barras
plt.figure(figsize=(10, 6))
bars = plt.bar(top_5_apps['App'], top_5_apps['Installs'], color='skyblue')
plt.title('Top 5 Apps por NÃºmero de InstalaÃ§Ãµes')
plt.xlabel('Apps')
plt.ylabel('NÃºmero de InstalaÃ§Ãµes')
plt.xticks(rotation=45)

# Adicionar os nÃºmeros de instalaÃ§Ãµes em cada barra
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval, f'{yval:,}', va='bottom', ha='center')

plt.tight_layout()
plt.show()
```
GrÃ¡fico em resposta do exercÃ­cio:

![GrÃ¡fico gerado](../evidencias/ev_desafio/ex2.png)

<br/>

## ğŸª Jupyter notebook - arquivo do desafio na Ã­ntegra

âš ï¸ **[Neste link conseguiremos acessar](../Desafio/desafio.ipynb) o arquivo notebook na Ã­ntegra com todos os cÃ³digos e respectivas respostas.**
<br/>

    Como Ã© esperado desse tipo de documento (*.ipynb), hÃ¡ blocos de cÃ³digo, as respectivas respostas de cada bloco e separaÃ§Ãµes entre esses blocos atravÃ©s de markdowns ğŸ“  

    Achei interessante esse recurso do Notebook, que permite uma organizaÃ§Ã£o e modularizaÃ§Ã£o do cÃ³digo. Compreendi que essa funcionalidade Ã© comumente utilizada para a organizaÃ§Ã£o de materiais de estudos, apostilagens, tutoriais, etc. ğŸ’¡ Isso fez muito sentido para mim! 

<br/>

# ğŸ“Œ ConsideraÃ§Ãµes finais sobre a sprint 03

Essa sprint, para mim, foi atÃ© aqui a mais desafiadora. ğŸ’ª
Senti-me parcialmente pronto para as lÃ³gicas a serem aplicadas, seja no tema de ETL, seja nos aspectos mais analÃ­ticos dos dados. No entanto, ao lidar com a linguagem de programaÃ§Ã£o e a possibilidade de orientaÃ§Ã£o a objetos, percebi que meu poder de abstraÃ§Ã£o precisa ser ainda mais desenvolvido. E achei Ã³tima essa oportunidade! ğŸŒ±

A sprint foi cansativa, mas extremamente recompensadora, especialmente no que diz respeito ao desenvolvimento do mindset do cientista de dados. ğŸ§ âœ¨

Compreendi tambÃ©m a importÃ¢ncia do ETL, um trabalho que, aparentemente, Ã© mais designado aos Engenheiros de Dados. Com tratamentos bem realizados, a chance de realizar anÃ¡lises de dados com mais qualidade e assertividade Ã© proporcionalmente maior! ğŸ“Š

Por fim, senti uma inclinaÃ§Ã£o maior pela anÃ¡lise de dados do que pela parte de engenharia. Ã‰ algo que vou manter em mente e observar mais de perto conforme avanÃ§o na bolsa de estudos e nas prÃ³ximas sprints. ğŸ”

---